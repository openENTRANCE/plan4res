#/bin/bash

# this scripts launches SSV alone

export P4R_SINGULARITY_IMAGE_PRESERVE=1 # avoid update of the container
export P4R_ENV="../bin/p4r"
export TIME_P4R_ENV="/usr/bin/time -v ${P4R_ENV}"
export PYTHONSCRIPTS="scripts/python/plan4res-scripts/"
export DATA="data/local/"

# DATASET is the name of the directory within data/local
if [ "$1" == "" ] ; then
    echo "provide name of dataset in data/local/"
    read DATASET
else
	echo $1
	DATASET=$1
	echo $DATASET
fi

export INSTANCE="${DATA}${DATASET}/"
export CONFIG="${DATA}${DATASET}/settings/"

# run script to create plan4res input dataset (ZV_ZineValues.csv ...)
# comment if you are using handmade datasets
#${P4R_ENV} python -W ignore ${PYTHONSCRIPTS}CreateInputPlan4res.py /${CONFIG}settingsCreateInputPlan4res_simul.yml ${DATASET}

# run formatting script to create netcdf input files
#${P4R_ENV} python -W ignore ${PYTHONSCRIPTS}format.py /${CONFIG}settings_format_optim.yml /${CONFIG}settingsCreateInputPlan4res_simul.yml ${DATASET}

# run sddp solver
${TIME_P4R_ENV} sddp_solver -S ${CONFIG}sddp_solver.txt -c ${CONFIG} -p ${INSTANCE}nc4_optim/ ${INSTANCE}nc4_optim/SDDPBlock.nc4

# for hotstart (if last run did not converge) use following line instead
#${TIME_P4R_ENV} sddp_solver -l ../cuts.txt -S ${CONFIG}sddp_solver2scen.txt -c ${CONFIG} -p ${INSTANCE}nc4_optim/ ${INSTANCE}nc4_optim/SDDPBlock.nc4

mkdir ../${INSTANCE}results/
mv ../Bellman* ../${INSTANCE}results/
mv ../cuts.txt ../${INSTANCE}results/
rm ../regressors.sddp.* ../visited_states.sddp.* ../cuts.sddp* ../uc.lp
cp ../${INSTANCE}results/cuts.txt ../${INSTANCE}bellmanvalues.csv
cp ../${INSTANCE}results/BellmanValuesOUT.csv ../${INSTANCE}bellmanvalues.csv
